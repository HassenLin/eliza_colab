{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HassenLin/eliza_colab/blob/main/HW3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1tbuxEx4dSnn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d7d22df-4ea4-4a43-ddd9-9880b95984fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.11/dist-packages (1.8.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torchvision import transforms\n",
        "import torchvision\n",
        "from torchinfo import summary\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import Literal\n",
        "import os\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import zipfile\n",
        "from glob import glob\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "import pandas as pd\n",
        "import cv2"
      ],
      "metadata": {
        "id": "YKw8M6hLdZby"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "dataset_path_str = r\"/content/data/Midterm_Project\"\n",
        "dataset_path = Path(dataset_path_str)\n",
        "\n",
        "for f in os.listdir(\"/content/drive/MyDrive/Colab Notebooks/data/\"):\n",
        " print(f)\n",
        "dataset_path.mkdir( parents=True, exist_ok=True )"
      ],
      "metadata": {
        "id": "3frM35mKeW9S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a76a794-ffd9-4ad7-c15b-ba08fad20a34"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Midterm_Project.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with zipfile.ZipFile(r\"/content/drive/MyDrive/Colab Notebooks/data/Midterm_Project.zip\", \"r\" ) as zip_ref:\n",
        "  zip_ref.extractall( dataset_path_str )"
      ],
      "metadata": {
        "id": "6LnK7yhB28Sr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for f in os.listdir(dataset_path):\n",
        " print(f)"
      ],
      "metadata": {
        "id": "ysLyIE_BfkQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mapping = {}\n",
        "for i, char in enumerate( \"0123456789+-*รท\") :\n",
        "   mapping[char] = i\n",
        "def normalize_label( label_str ):\n",
        "  ret=\"\"\n",
        "  for i, char in enumerate( label_str ) :\n",
        "    if char in mapping:\n",
        "      ret= ret + char\n",
        "  return ret"
      ],
      "metadata": {
        "id": "HmoNg7f_5pTp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def label_to_tensor( label_str ):\n",
        "  t=[]\n",
        "  for i, char in enumerate( label_str ) :\n",
        "    if char in mapping:\n",
        "      t.append(mapping[char])\n",
        "    else:\n",
        "      print(label_str + \" has '\"+char+\"'\")\n",
        "  return torch.tensor( t, dtype = torch.long )"
      ],
      "metadata": {
        "id": "mT_zS6Bv1-o8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CatchDataset(Dataset):\n",
        "  def __init__( self, split:Literal[\"train_data01\", \"train_data02\"], transform:transforms=None ) -> None:\n",
        "    super().__init__()\n",
        "\n",
        "    self.transform = transform\n",
        "\n",
        "    if split == \"train_data01\":\n",
        "      csv_path = os.path.join( dataset_path, \"train_data01.csv\" )\n",
        "      img_dir = os.path.join( dataset_path, \"train_data01\" )\n",
        "    elif split == \"train_data02\":\n",
        "      csv_path = os.path.join( dataset_path, \"train_data02.csv\" )\n",
        "      img_dir = os.path.join( dataset_path, \"train_data02\" )\n",
        "    self.imgs = []\n",
        "    self.labels = []\n",
        "    df = pd.read_csv( csv_path, sep='\\t', lineterminator='\\n' )\n",
        "    # print( df.head() )\n",
        "    # print( df.shape )\n",
        "    for _, row in df.iterrows():\n",
        "      if len(row) >= 3:\n",
        "        filename = str(os.path.join(img_dir, \"p\"+str(row.iloc[0])+\".jpg\"))\n",
        "        label = normalize_label(str(row.iloc[1])) # +\"\\t\"+ str(row.iloc[2])\n",
        "        if os.path.exists(filename):\n",
        "          self.imgs.append(filename)\n",
        "          self.labels.append(label)\n",
        "        else:\n",
        "          print(filename + \" not exist!!\")\n",
        "    for i in range(0, 10) :\n",
        "        print(self.imgs[i] +\" ==> \"+ self.labels[i])\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.imgs)\n",
        "\n",
        "  def __getitem__( self, index ):\n",
        "    image_path = self.imgs[index]\n",
        "    label = self.labels[index]\n",
        "\n",
        "    image = cv2.imread(image_path)\n",
        "    img_np = np.array( image )\n",
        "    img_gray = cv2.cvtColor( img_np, cv2.COLOR_BGR2GRAY)\n",
        "    img_denoise = cv2.fastNlMeansDenoising( img_gray )\n",
        "\n",
        "    canny = cv2.Canny( img_denoise, 150, 200 )\n",
        "    canny_dilate = cv2.dilate( canny, np.ones( (3, 3), np.uint8) )\n",
        "    contours, _ = cv2.findContours( canny_dilate, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE )\n",
        "\n",
        "    contour_sort = sorted( [(c, cv2.boundingRect(c)[0]) for c in contours], key = lambda x: x[1] )\n",
        "    filter_contours = []\n",
        "    for ( c, _ ) in contour_sort:\n",
        "      x, y, w, h = cv2.boundingRect(c)\n",
        "      area = w * h\n",
        "      if area > 15:\n",
        "        filter_contours.append( (x, y, w, h) )\n",
        "\n",
        "    characters_imgs = []\n",
        "    for x, y, w, h in filter_contours:\n",
        "      char_img = img_gray[ y:y + h, x: x + w ]\n",
        "      char_img = cv2.resize( char_img, (32, 32) )\n",
        "      char_img = cv2.cvtColor( char_img, cv2.COLOR_GRAY2RGB )\n",
        "      char_img = Image.fromarray( char_img )\n",
        "      char_img = self.transform( char_img )\n",
        "      characters_imgs.append( char_img )\n",
        "    while len( characters_imgs ) < 9:\n",
        "      characters_imgs.append( torch.zeros((3, 32, 32)) )\n",
        "    characters_imgs = characters_imgs[:9]\n",
        "\n",
        "    characters_imgs = torch.stack( characters_imgs )\n",
        "    label_tensor = label_to_tensor( label )\n",
        "    return characters_imgs, label_tensor"
      ],
      "metadata": {
        "id": "RNhEbyHafSKj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize( mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225] )\n",
        "])"
      ],
      "metadata": {
        "id": "l8rg65WVhl_B"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "full_dataset = CatchDataset( split=\"train_data01\", transform=transform )\n",
        "\n",
        "train_indices, val_indices = train_test_split(\n",
        "    list( range( len(full_dataset) ) ),\n",
        "    test_size = 0.2,\n",
        "    random_state = 1,\n",
        "    shuffle = True\n",
        ")\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "val_sampler = SubsetRandomSampler(val_indices)\n",
        "train_loader = DataLoader( full_dataset, sampler=train_sampler, batch_size=32, shuffle=False )\n",
        "val_loader = DataLoader( full_dataset, sampler=val_sampler, batch_size=32, shuffle=False )"
      ],
      "metadata": {
        "id": "hpmF_3a9iA23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89244e10-3eb6-4e48-e29a-f9fe5af5d89c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/data/Midterm_Project/train_data01/p1.jpg ==> 13*513032\n",
            "/content/data/Midterm_Project/train_data01/p2.jpg ==> 785+38787\n",
            "/content/data/Midterm_Project/train_data01/p3.jpg ==> 3+49807+8\n",
            "/content/data/Midterm_Project/train_data01/p4.jpg ==> 3*3585982\n",
            "/content/data/Midterm_Project/train_data01/p5.jpg ==> 5*9*18652\n",
            "/content/data/Midterm_Project/train_data01/p6.jpg ==> 5483+1815\n",
            "/content/data/Midterm_Project/train_data01/p7.jpg ==> 77+7*97+7\n",
            "/content/data/Midterm_Project/train_data01/p8.jpg ==> 8-80+6-74\n",
            "/content/data/Midterm_Project/train_data01/p9.jpg ==> 7+4653543\n",
            "/content/data/Midterm_Project/train_data01/p10.jpg ==> 4+471*8*9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ResBlock(nn.Module):\n",
        "\n",
        "  def __init__( self, in_channels, out_channels, stride=1 ):\n",
        "    super().__init__()\n",
        "    self.res_function = nn.Sequential(\n",
        "        nn.Conv2d( in_channels=in_channels, out_channels=out_channels, kernel_size=3, stride=stride, padding=1 ),\n",
        "        nn.BatchNorm2d( out_channels ),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d( in_channels=out_channels, out_channels=out_channels, kernel_size=3, stride=1, padding=1 ),\n",
        "        nn.BatchNorm2d( out_channels )\n",
        "    )\n",
        "    self.identity_function = nn.Sequential()\n",
        "    if stride != 1 or in_channels != out_channels:\n",
        "      self.identity_function = nn.Sequential(\n",
        "          nn.Conv2d( in_channels, out_channels, kernel_size=1, stride=stride, bias=False ),\n",
        "          nn.BatchNorm2d( out_channels )\n",
        "      )\n",
        "\n",
        "  def forward( self, x ):\n",
        "    identity = self.identity_function( x )\n",
        "    out = self.res_function( x )\n",
        "    out += identity\n",
        "    return F.relu( out )\n",
        "\n",
        "class ResNet18(nn.Module):\n",
        "\n",
        "  def __init__( self, Resblock, num_blocks ):\n",
        "    super().__init__()\n",
        "    self.in_channels = 64\n",
        "    self.conv1 = nn.Sequential(\n",
        "        nn.Conv2d( in_channels=3, out_channels=64, kernel_size=3, padding=1 ),\n",
        "        nn.BatchNorm2d( 64 ),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "    self.conv2_x = self._make_layer( Resblock, 64, num_blocks[0], 1 )\n",
        "    self.conv3_x = self._make_layer( Resblock, 128, num_blocks[1], 1 )\n",
        "    self.conv4_x = self._make_layer( Resblock, 256, num_blocks[2], 1 )\n",
        "    self.conv5_x = self._make_layer( Resblock, 512, num_blocks[3], 1 )\n",
        "\n",
        "    self.avg_pooling = nn.AdaptiveAvgPool2d( (1,1) )\n",
        "    self.dropout = nn.Dropout( 0.5 )\n",
        "    self.fc = nn.Linear( 512, 14 )\n",
        "\n",
        "  def _make_layer( self, Resblock, out_channels, num_blocks, stride ):\n",
        "    strides = [stride] + [1] * ( num_blocks - 1 )\n",
        "    layers = []\n",
        "    for stride in strides:\n",
        "      layers.append( Resblock( self.in_channels, out_channels, stride) )\n",
        "      self.in_channels = out_channels\n",
        "    return nn.Sequential( *layers )\n",
        "\n",
        "  def forward( self, x ):\n",
        "    x = self.conv1(x)\n",
        "    x = self.conv2_x(x)\n",
        "    x = self.conv3_x(x)\n",
        "    x = self.conv4_x(x)\n",
        "    x = self.conv5_x(x)\n",
        "    x = self.avg_pooling(x)\n",
        "    x = torch.flatten( x, 1 )\n",
        "    x = self.dropout(x)\n",
        "    x = self.fc(x)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "VeNNzb4IzcJe"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = torch.device( \"cuda\" if torch.cuda.is_available() else \"cpu\" )\n",
        "model = ResNet18( ResBlock, [2, 2, 2, 2] )\n",
        "model = model.to(DEVICE)"
      ],
      "metadata": {
        "id": "wbG17H7vdDxM"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_func = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD( model.parameters(), lr = 1e-3, momentum = 0.9 )"
      ],
      "metadata": {
        "id": "0zLNE5k-yIlI"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_list = []\n",
        "test_loss_list = []\n",
        "train_acc_list = []\n",
        "test_acc_list = []\n",
        "\n",
        "EPOCH = 30\n",
        "patience = 10\n",
        "early_stop = 0\n",
        "best_test_acc = 0.0\n",
        "\n",
        "for epoch in range(EPOCH):\n",
        "  model.train()\n",
        "  epoch_loss = 0.0\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  print(f'Epoch: {epoch+1} :')\n",
        "  for idx, (img, labels) in enumerate(train_loader):\n",
        "    img = img.to(DEVICE)\n",
        "    labels = labels.to(DEVICE)\n",
        "    optimizer.zero_grad()\n",
        "    batch_loss = 0.0\n",
        "    print(f'  idx: {idx}', end='')\n",
        "    for i in range(9):\n",
        "      char_imgs = img[:, i, :, :, :]\n",
        "      char_labels = labels[ :, i ]\n",
        "      outputs = model( char_imgs )\n",
        "      loss = loss_func( outputs, char_labels )\n",
        "      batch_loss += loss\n",
        "\n",
        "      _, pred = torch.max( outputs, dim=1 )\n",
        "      correct += ( pred == char_labels ).sum().item()\n",
        "      total += char_imgs.shape[0]\n",
        "      print('.', end='')\n",
        "    print('|')\n",
        "    batch_loss.backward()\n",
        "    optimizer.step()\n",
        "    epoch_loss += batch_loss.item()\n",
        "\n",
        "  avg_loss = epoch_loss / len( train_loader )\n",
        "  loss_list.append( avg_loss )\n",
        "  train_acc_list.append( correct / total )\n",
        "  print( f'\\tTrain Loss: {avg_loss:.3f} \\tTrain Acc: {100 * correct / total:.2f}%')\n",
        "\n",
        "  model.eval()\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  test_loss = 0.0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for idx, (img, labels) in enumerate(val_loader):\n",
        "      img = img.to(DEVICE)\n",
        "      labels = labels.to(DEVICE)\n",
        "      batch_loss = 0.0\n",
        "\n",
        "      for i in range(9):\n",
        "        char_imgs = img[:, i, :, :, :]\n",
        "        char_labels = labels[:, i]\n",
        "        outputs = model( char_imgs )\n",
        "        loss = loss_func( outputs, labels )\n",
        "        batch_loss += loss\n",
        "\n",
        "        _, pred = torch.max( outputs, dim=1 )\n",
        "        correct += ( pred == char_labels ).sum().item()\n",
        "        total += char_imgs.shape[0]\n",
        "\n",
        "      test_loss += batch_loss.item()\n",
        "\n",
        "  avg_test_loss = test_loss / len( val_loader )\n",
        "  test_loss_list.append( avg_test_loss )\n",
        "  test_acc = correct / total\n",
        "  test_acc_list.append( test_acc )\n",
        "  print(f\"Epoch: {epoch + 1}\\tTest Loss: {avg_test_loss:.3f} \\tTest Acc: {100 * test_acc:.2f}%\")\n",
        "\n",
        "  if test_acc > best_test_acc:\n",
        "    best_test_acc = test_acc\n",
        "    early_stop = 0\n",
        "    # torch.save( model.state_dict(), \"model.pth\" )\n",
        "  else:\n",
        "    early_stop += 1\n",
        "\n",
        "  if early_stop >= patience:\n",
        "    break"
      ],
      "metadata": {
        "id": "Dg67xvvoojWP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f96dfbe-02b0-4bde-df6c-4f8a30e3c801"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 :\n",
            "  idx: 0.........|\n",
            "  idx: 1.........|\n",
            "  idx: 2........"
          ]
        }
      ]
    }
  ]
}